{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff3fc8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë ·∫£nh: 164\n",
      "T·ªïng s·ªë metadata entries: 152\n",
      "ƒê√£ ch·ªçn 164 ·∫£nh\n",
      "ƒê√£ copy 164 ·∫£nh v√†o /home/hungnq/hungnq/sd_stuff/notebook/experiment_2/selected_200_ids\n",
      "ƒê√£ l∆∞u metadata v·ªõi 164 entries v√†o /home/hungnq/hungnq/sd_stuff/notebook/experiment_2/selected_200_ids/metadata.json\n",
      "\n",
      "Ho√†n th√†nh! Folder selected_200_ids ƒë√£ ƒë∆∞·ª£c t·∫°o t·∫°i: /home/hungnq/hungnq/sd_stuff/notebook/experiment_2/selected_200_ids\n",
      "T·∫•t c·∫£ ·∫£nh ƒë∆∞·ª£c ƒë√°nh s·ªë t·ª´ 1 ƒë·∫øn 164\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi c√°c folders\n",
    "base_path = Path(\"/home/hungnq/hungnq/sd_stuff/notebook/experiment_2\")\n",
    "folders = [\n",
    "    \"prompt_variations_images_batch_0_50_2\",\n",
    "    \"prompt_variations_images_batch_50_100\",\n",
    "    \"prompt_variations_images_batch_100_150\",\n",
    "    \"prompt_variations_images_batch_150_200_2\"\n",
    "]\n",
    "\n",
    "# ƒê·ªçc t·∫•t c·∫£ metadata t·ª´ 4 folders\n",
    "all_images = []  # L∆∞u tr·ªØ (folder, img_folder, image_path, metadata_key)\n",
    "all_metadata = {}\n",
    "\n",
    "for folder in folders:\n",
    "    metadata_path = base_path / folder / \"metadata.json\"\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "        all_metadata.update(metadata)\n",
    "        \n",
    "        # L·∫•y danh s√°ch image folders trong folder n√†y\n",
    "        folder_path = base_path / folder\n",
    "        image_folders = [d for d in os.listdir(folder_path) if d.startswith('image_') and os.path.isdir(folder_path / d)]\n",
    "        \n",
    "        for img_folder in image_folders:\n",
    "            # T√¨m t·∫•t c·∫£ ·∫£nh trong img_folder\n",
    "            img_folder_path = folder_path / img_folder\n",
    "            image_files = list(img_folder_path.glob('*.png')) + list(img_folder_path.glob('*.jpg'))\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                # T√¨m metadata key t∆∞∆°ng ·ª©ng\n",
    "                img_id = img_folder.split('_')[1]  # '0001'\n",
    "                for key in all_metadata.keys():\n",
    "                    if f\"img{img_id}_\" in key and img_file.stem in key:\n",
    "                        all_images.append((folder, img_folder, img_file, key))\n",
    "                        break\n",
    "\n",
    "print(f\"T·ªïng s·ªë ·∫£nh: {len(all_images)}\")\n",
    "print(f\"T·ªïng s·ªë metadata entries: {len(all_metadata)}\")\n",
    "\n",
    "# Ch·ªçn 200 ·∫£nh ng·∫´u nhi√™n\n",
    "random.seed(42)  # ƒê·ªÉ k·∫øt qu·∫£ c√≥ th·ªÉ t√°i t·∫°o\n",
    "selected_images = random.sample(all_images, min(200, len(all_images)))\n",
    "\n",
    "print(f\"ƒê√£ ch·ªçn {len(selected_images)} ·∫£nh\")\n",
    "\n",
    "# T·∫°o folder selected_200_ids (x√≥a n·∫øu ƒë√£ t·ªìn t·∫°i ƒë·ªÉ tr√°nh l·ªói)\n",
    "output_folder = base_path / \"selected_200_ids\"\n",
    "if output_folder.exists():\n",
    "    shutil.rmtree(output_folder)\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy c√°c ·∫£nh ƒë√£ ch·ªçn v·ªõi t√™n ƒë√°nh s·ªë t·ª´ 1 ƒë·∫øn 200\n",
    "selected_metadata = {}\n",
    "for idx, (source_folder, img_folder, img_path, metadata_key) in enumerate(selected_images, start=1):\n",
    "    # L·∫•y extension c·ªßa ·∫£nh\n",
    "    ext = img_path.suffix\n",
    "    \n",
    "    # T√™n file m·ªõi: 1.png, 2.png, ..., 200.png\n",
    "    new_filename = f\"{idx}{ext}\"\n",
    "    dest_path = output_folder / new_filename\n",
    "    \n",
    "    # Copy ·∫£nh\n",
    "    shutil.copy2(img_path, dest_path)\n",
    "    \n",
    "    # C·∫≠p nh·∫≠t metadata\n",
    "    if metadata_key in all_metadata:\n",
    "        new_value = all_metadata[metadata_key].copy()\n",
    "        new_value['local_path'] = f\"selected_200_ids/{new_filename}\"\n",
    "        new_value['new_id'] = idx\n",
    "        new_value['original_folder'] = source_folder\n",
    "        new_value['original_image_folder'] = img_folder\n",
    "        selected_metadata[f\"img{idx:04d}\"] = new_value\n",
    "\n",
    "print(f\"ƒê√£ copy {len(selected_images)} ·∫£nh v√†o {output_folder}\")\n",
    "\n",
    "# L∆∞u metadata m·ªõi\n",
    "metadata_output_path = output_folder / \"metadata.json\"\n",
    "with open(metadata_output_path, 'w') as f:\n",
    "    json.dump(selected_metadata, f, indent=2)\n",
    "\n",
    "print(f\"ƒê√£ l∆∞u metadata v·ªõi {len(selected_metadata)} entries v√†o {metadata_output_path}\")\n",
    "print(f\"\\nHo√†n th√†nh! Folder selected_200_ids ƒë√£ ƒë∆∞·ª£c t·∫°o t·∫°i: {output_folder}\")\n",
    "print(f\"T·∫•t c·∫£ ·∫£nh ƒë∆∞·ª£c ƒë√°nh s·ªë t·ª´ 1 ƒë·∫øn {len(selected_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee69bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prompt_variations_images_batch_0_50:\n",
      "  - S·ªë image folders: 39\n",
      "  - T·ªïng s·ªë ·∫£nh: 51\n",
      "  - Folders c√≥ nhi·ªÅu h∆°n 1 ·∫£nh: 4\n",
      "    + image_0001: 5 ·∫£nh - ['var2_male.png', 'var3_male.png', 'var4_male.png', 'var1_male.png', 'base_male.png']\n",
      "    + image_0002: 4 ·∫£nh - ['var2_male.png', 'var3_male.png', 'var4_male.png', 'var1_male.png']\n",
      "    + image_0003: 4 ·∫£nh - ['var2_male.png', 'var3_male.png', 'var1_male.png', 'base_male.png']\n",
      "    + image_0005: 3 ·∫£nh - ['var2_male.png', 'var1_male.png', 'base_male.png']\n",
      "\n",
      "prompt_variations_images_batch_50_100:\n",
      "  - S·ªë image folders: 48\n",
      "  - T·ªïng s·ªë ·∫£nh: 48\n",
      "\n",
      "prompt_variations_images_batch_100_150:\n",
      "  - S·ªë image folders: 37\n",
      "  - T·ªïng s·ªë ·∫£nh: 36\n",
      "  - Folders kh√¥ng c√≥ ·∫£nh: 1\n",
      "    + image_0037\n",
      "\n",
      "prompt_variations_images_batch_150_200_2:\n",
      "  - S·ªë image folders: 45\n",
      "  - T·ªïng s·ªë ·∫£nh: 42\n",
      "  - Folders kh√¥ng c√≥ ·∫£nh: 3\n",
      "    + image_0040\n",
      "    + image_0046\n",
      "    + image_0017\n",
      "\n",
      "============================================================\n",
      "T·ªîNG C·ªòNG: 177 ·∫£nh t·ª´ t·∫•t c·∫£ c√°c folders\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ƒêi·ªÅu tra chi ti·∫øt s·ªë l∆∞·ª£ng ·∫£nh trong m·ªói folder\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"/home/hungnq/hungnq/sd_stuff/notebook/experiment_2\")\n",
    "folders = [\n",
    "    \"prompt_variations_images_batch_0_50\",\n",
    "    \"prompt_variations_images_batch_50_100\",\n",
    "    \"prompt_variations_images_batch_100_150\",\n",
    "    \"prompt_variations_images_batch_150_200_2\"\n",
    "]\n",
    "\n",
    "total_images = 0\n",
    "folder_stats = {}\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = base_path / folder\n",
    "    \n",
    "    # ƒê·∫øm s·ªë image folders\n",
    "    image_folders = [d for d in os.listdir(folder_path) if d.startswith('image_') and os.path.isdir(folder_path / d)]\n",
    "    \n",
    "    # ƒê·∫øm t·ªïng s·ªë ·∫£nh\n",
    "    image_count = 0\n",
    "    image_details = []\n",
    "    \n",
    "    for img_folder in image_folders:\n",
    "        img_folder_path = folder_path / img_folder\n",
    "        images = list(img_folder_path.glob('*.png')) + list(img_folder_path.glob('*.jpg'))\n",
    "        image_count += len(images)\n",
    "        image_details.append({\n",
    "            'folder': img_folder,\n",
    "            'num_images': len(images),\n",
    "            'images': [img.name for img in images]\n",
    "        })\n",
    "    \n",
    "    folder_stats[folder] = {\n",
    "        'num_image_folders': len(image_folders),\n",
    "        'total_images': image_count,\n",
    "        'details': image_details\n",
    "    }\n",
    "    \n",
    "    total_images += image_count\n",
    "    \n",
    "    print(f\"\\n{folder}:\")\n",
    "    print(f\"  - S·ªë image folders: {len(image_folders)}\")\n",
    "    print(f\"  - T·ªïng s·ªë ·∫£nh: {image_count}\")\n",
    "    \n",
    "    # Ki·ªÉm tra n·∫øu c√≥ folder n√†o c√≥ nhi·ªÅu h∆°n 1 ·∫£nh\n",
    "    multi_image_folders = [d for d in image_details if d['num_images'] > 1]\n",
    "    if multi_image_folders:\n",
    "        print(f\"  - Folders c√≥ nhi·ªÅu h∆°n 1 ·∫£nh: {len(multi_image_folders)}\")\n",
    "        for item in multi_image_folders[:5]:  # Show first 5\n",
    "            print(f\"    + {item['folder']}: {item['num_images']} ·∫£nh - {item['images']}\")\n",
    "    \n",
    "    # Ki·ªÉm tra n·∫øu c√≥ folder n√†o kh√¥ng c√≥ ·∫£nh\n",
    "    empty_folders = [d for d in image_details if d['num_images'] == 0]\n",
    "    if empty_folders:\n",
    "        print(f\"  - Folders kh√¥ng c√≥ ·∫£nh: {len(empty_folders)}\")\n",
    "        for item in empty_folders[:5]:\n",
    "            print(f\"    + {item['folder']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"T·ªîNG C·ªòNG: {total_images} ·∫£nh t·ª´ t·∫•t c·∫£ c√°c folders\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf2bf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë d√≤ng trong CSV: 199\n",
      "C√°c c·ªôt: ['Images', 'gender', 'image_path', 'base_prompt', 'variation_1_prompt', 'variation_2_prompt', 'variation_3_prompt', 'variation_4_prompt']\n",
      "\n",
      "S·ªë l∆∞·ª£ng ·∫£nh unique: 146\n",
      "\n",
      "C√°c c·ªôt prompt: ['base_prompt', 'variation_1_prompt', 'variation_2_prompt', 'variation_3_prompt', 'variation_4_prompt']\n",
      "\n",
      "S·ªë d√≤ng c√≥ base_prompt: 199\n",
      "S·ªë d√≤ng c√≥ variation_1_prompt: 4\n",
      "S·ªë d√≤ng c√≥ variation_2_prompt: 4\n",
      "S·ªë d√≤ng c√≥ variation_3_prompt: 3\n",
      "S·ªë d√≤ng c√≥ variation_4_prompt: 2\n",
      "\n",
      "============================================================\n",
      "\n",
      "S·ªë ·∫£nh trong selected_200_ids: 164\n",
      "S·ªë image_name unique trong metadata: 129\n",
      "S·ªë Images trong CSV: 146\n",
      "\n",
      "·∫¢nh c√≥ trong CSV nh∆∞ng KH√îNG c√≥ trong selected_200_ids: 17\n",
      "Danh s√°ch (10 ƒë·∫ßu ti√™n): ['13.jpg', '14.jpg', '24.jpg', '28.jpg', '3.jpg', '30.jpg', '4.jpg', '41.jpg', '42.jpg', 'Image_25.jpg']\n",
      "\n",
      "·∫¢nh c√≥ ·ªü C·∫¢ HAI n∆°i: 129\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Ph√¢n t√≠ch file CSV ƒë·ªÉ ki·ªÉm tra s·ªë l∆∞·ª£ng prompts\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"/home/hungnq/hungnq/sd_stuff/notebook/experiment_2\")\n",
    "csv_file = base_path / \"prompt_base_and_variations_full.csv\"\n",
    "\n",
    "# ƒê·ªçc CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"T·ªïng s·ªë d√≤ng trong CSV: {len(df)}\")\n",
    "print(f\"C√°c c·ªôt: {df.columns.tolist()}\")\n",
    "print()\n",
    "\n",
    "# Ki·ªÉm tra s·ªë l∆∞·ª£ng ·∫£nh unique\n",
    "unique_images = df['Images'].unique()\n",
    "print(f\"S·ªë l∆∞·ª£ng ·∫£nh unique: {len(unique_images)}\")\n",
    "print()\n",
    "\n",
    "# Ki·ªÉm tra c√°c c·ªôt prompt\n",
    "prompt_columns = [col for col in df.columns if 'prompt' in col.lower()]\n",
    "print(f\"C√°c c·ªôt prompt: {prompt_columns}\")\n",
    "print()\n",
    "\n",
    "# ƒê·∫øm s·ªë d√≤ng c√≥ base_prompt\n",
    "has_base_prompt = df['base_prompt'].notna().sum()\n",
    "print(f\"S·ªë d√≤ng c√≥ base_prompt: {has_base_prompt}\")\n",
    "\n",
    "# ƒê·∫øm s·ªë d√≤ng c√≥ variation prompts\n",
    "for col in prompt_columns:\n",
    "    if 'variation' in col:\n",
    "        has_prompt = df[col].notna().sum()\n",
    "        print(f\"S·ªë d√≤ng c√≥ {col}: {has_prompt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Ki·ªÉm tra c√°c ·∫£nh trong CSV vs ·∫£nh trong selected_200_ids\n",
    "selected_folder = base_path / \"selected_200_ids\"\n",
    "if selected_folder.exists():\n",
    "    # ƒê·ªçc metadata\n",
    "    metadata_file = selected_folder / \"metadata.json\"\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"\\nS·ªë ·∫£nh trong selected_200_ids: {len(metadata)}\")\n",
    "    \n",
    "    # L·∫•y danh s√°ch image_name t·ª´ metadata\n",
    "    image_names_in_selected = set()\n",
    "    for key, value in metadata.items():\n",
    "        if 'image_name' in value:\n",
    "            image_names_in_selected.add(value['image_name'])\n",
    "    \n",
    "    print(f\"S·ªë image_name unique trong metadata: {len(image_names_in_selected)}\")\n",
    "    \n",
    "    # So s√°nh v·ªõi CSV\n",
    "    image_names_in_csv = set(df['Images'].tolist())\n",
    "    print(f\"S·ªë Images trong CSV: {len(image_names_in_csv)}\")\n",
    "    \n",
    "    # T√¨m ·∫£nh c√≥ trong selected nh∆∞ng kh√¥ng c√≥ trong CSV\n",
    "    missing_in_csv = image_names_in_selected - image_names_in_csv\n",
    "    if missing_in_csv:\n",
    "        print(f\"\\n·∫¢nh c√≥ trong selected_200_ids nh∆∞ng KH√îNG c√≥ trong CSV: {len(missing_in_csv)}\")\n",
    "        print(f\"Danh s√°ch: {sorted(missing_in_csv)[:10]}\")\n",
    "    \n",
    "    # T√¨m ·∫£nh c√≥ trong CSV nh∆∞ng kh√¥ng c√≥ trong selected\n",
    "    missing_in_selected = image_names_in_csv - image_names_in_selected\n",
    "    if missing_in_selected:\n",
    "        print(f\"\\n·∫¢nh c√≥ trong CSV nh∆∞ng KH√îNG c√≥ trong selected_200_ids: {len(missing_in_selected)}\")\n",
    "        print(f\"Danh s√°ch (10 ƒë·∫ßu ti√™n): {sorted(missing_in_selected)[:10]}\")\n",
    "    \n",
    "    # T√¨m ·∫£nh c√≥ ·ªü c·∫£ hai\n",
    "    in_both = image_names_in_selected & image_names_in_csv\n",
    "    print(f\"\\n·∫¢nh c√≥ ·ªü C·∫¢ HAI n∆°i: {len(in_both)}\")\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab18823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë d√≤ng trong CSV: 199\n",
      "S·ªë ·∫£nh unique: 146\n",
      "\n",
      "S·ªë ·∫£nh b·ªã l·∫∑p: 53\n",
      "T·ªïng s·ªë l·∫ßn l·∫∑p: 106 (t√≠nh c·∫£ b·∫£n g·ªëc)\n",
      "S·ªë d√≤ng th·ª´a do l·∫∑p: 53\n",
      "\n",
      "================================================================================\n",
      "DANH S√ÅCH ·∫¢NH B·ªä L·∫∂P:\n",
      "================================================================================\n",
      "\n",
      "1.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 2: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/1.jpg\n",
      "         C√≥ prompts: base_prompt, variation_1, variation_2, variation_3, variation_4\n",
      "  D√≤ng 101: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/1.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_44.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 50: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_44.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 155: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_44.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "30.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 31: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/30.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 130: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/30.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_13.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 32: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_13.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 136: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_13.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_24.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 37: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_24.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 141: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_24.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_28.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 39: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_28.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 144: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_28.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_3.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 41: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_3.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 133: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_3.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_30.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 42: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_30.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 145: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_30.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_31.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 43: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_31.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 146: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_31.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_33.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 44: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_33.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 148: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_33.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_34.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 45: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_34.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 149: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_34.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_39.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 48: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_39.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 152: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_39.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_4.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 49: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_4.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 134: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_4.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_48.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 53: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_48.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 159: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_48.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "28.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 29: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/28.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 128: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/28.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_49.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 54: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_49.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 160: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_49.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_51.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 57: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_51.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 161: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_51.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_56.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 61: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_56.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 162: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_56.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_62.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 65: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_62.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 165: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_62.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_65.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 67: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_65.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 166: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_65.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_67.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 69: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_67.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 167: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_67.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_70.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 72: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_70.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 168: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_70.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_73.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 74: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_73.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 170: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_73.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "2.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 3: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/2.jpg\n",
      "         C√≥ prompts: base_prompt, variation_1, variation_2, variation_3, variation_4\n",
      "  D√≤ng 102: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/2.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_90.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 78: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_90.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 175: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_90.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_91.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 79: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_91.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 176: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_91.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "29.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 30: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/29.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 129: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/29.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "Image_47.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 51: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/Image_47.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 158: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/Image_47.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "27.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 28: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/27.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 127: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/27.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "17.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 18: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/17.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 117: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/17.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "3.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 4: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/3.jpg\n",
      "         C√≥ prompts: base_prompt, variation_1, variation_2, variation_3\n",
      "  D√≤ng 103: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/3.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "4.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 5: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/4.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 104: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/4.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "5.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 6: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/5.jpg\n",
      "         C√≥ prompts: base_prompt, variation_1, variation_2\n",
      "  D√≤ng 105: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/5.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "6.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 7: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/6.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 106: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/6.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "7.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 8: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/7.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 107: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/7.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "8.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 9: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/8.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 108: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/8.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "9.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 10: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/9.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 109: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/9.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "26.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 27: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/26.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 126: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/26.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "11.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 12: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/11.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 111: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/11.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "12.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 13: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/12.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 112: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/12.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "13.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 14: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/13.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 113: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/13.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "14.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 15: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/14.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 114: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/14.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "15.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 16: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/15.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 115: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/15.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "16.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 17: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/16.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 116: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/16.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "10.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 11: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/10.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 110: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/10.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "25.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 26: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/25.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 125: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/25.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "18.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 19: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/18.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 118: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/18.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "19.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 20: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/19.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 119: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/19.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "20.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 21: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/20.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 120: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/20.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "21.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 22: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/21.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 121: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/21.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "23.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 24: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/23.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 123: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/23.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "24.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 25: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/24.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 124: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/24.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "22.jpg: xu·∫•t hi·ªán 2 l·∫ßn\n",
      "  D√≤ng 23: gender=male, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male/22.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "  D√≤ng 122: gender=female, image_path=/home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female/22.jpg\n",
      "         C√≥ prompts: base_prompt\n",
      "\n",
      "================================================================================\n",
      "\n",
      "T√ìM T·∫ÆT:\n",
      "  - T·ªïng s·ªë d√≤ng: 199\n",
      "  - S·ªë ·∫£nh unique: 146\n",
      "  - S·ªë d√≤ng b·ªã l·∫∑p th·ª´a: 53\n",
      "  - N·∫øu x√≥a d√≤ng l·∫∑p s·∫Ω c√≤n: 146 d√≤ng\n"
     ]
    }
   ],
   "source": [
    "# T√¨m ·∫£nh b·ªã l·∫∑p trong CSV\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"/home/hungnq/hungnq/sd_stuff/notebook/experiment_2\")\n",
    "csv_file = base_path / \"prompt_base_and_variations_full.csv\"\n",
    "\n",
    "# ƒê·ªçc CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"T·ªïng s·ªë d√≤ng trong CSV: {len(df)}\")\n",
    "print(f\"S·ªë ·∫£nh unique: {df['Images'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# T√¨m ·∫£nh b·ªã l·∫∑p\n",
    "image_counts = df['Images'].value_counts()\n",
    "duplicated_images = image_counts[image_counts > 1]\n",
    "\n",
    "print(f\"S·ªë ·∫£nh b·ªã l·∫∑p: {len(duplicated_images)}\")\n",
    "print(f\"T·ªïng s·ªë l·∫ßn l·∫∑p: {duplicated_images.sum()} (t√≠nh c·∫£ b·∫£n g·ªëc)\")\n",
    "print(f\"S·ªë d√≤ng th·ª´a do l·∫∑p: {duplicated_images.sum() - len(duplicated_images)}\")\n",
    "print()\n",
    "\n",
    "if len(duplicated_images) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"DANH S√ÅCH ·∫¢NH B·ªä L·∫∂P:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for img_name, count in duplicated_images.items():\n",
    "        print(f\"\\n{img_name}: xu·∫•t hi·ªán {count} l·∫ßn\")\n",
    "        \n",
    "        # L·∫•y t·∫•t c·∫£ c√°c d√≤ng c·ªßa ·∫£nh n√†y\n",
    "        img_rows = df[df['Images'] == img_name]\n",
    "        \n",
    "        for idx, row in img_rows.iterrows():\n",
    "            print(f\"  D√≤ng {idx + 2}: gender={row['gender']}, image_path={row['image_path']}\")\n",
    "            \n",
    "            # Ki·ªÉm tra xem c√≥ prompt n√†o kh√¥ng\n",
    "            has_base = pd.notna(row['base_prompt'])\n",
    "            has_var1 = pd.notna(row['variation_1_prompt'])\n",
    "            has_var2 = pd.notna(row['variation_2_prompt'])\n",
    "            has_var3 = pd.notna(row['variation_3_prompt'])\n",
    "            has_var4 = pd.notna(row['variation_4_prompt'])\n",
    "            \n",
    "            prompts_info = []\n",
    "            if has_base:\n",
    "                prompts_info.append(\"base_prompt\")\n",
    "            if has_var1:\n",
    "                prompts_info.append(\"variation_1\")\n",
    "            if has_var2:\n",
    "                prompts_info.append(\"variation_2\")\n",
    "            if has_var3:\n",
    "                prompts_info.append(\"variation_3\")\n",
    "            if has_var4:\n",
    "                prompts_info.append(\"variation_4\")\n",
    "            \n",
    "            if prompts_info:\n",
    "                print(f\"         C√≥ prompts: {', '.join(prompts_info)}\")\n",
    "            else:\n",
    "                print(f\"         Kh√¥ng c√≥ prompt n√†o\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# T√≠nh to√°n t·ªïng h·ª£p\n",
    "total_rows = len(df)\n",
    "unique_images = df['Images'].nunique()\n",
    "duplicate_rows = total_rows - unique_images\n",
    "\n",
    "print(f\"\\nT√ìM T·∫ÆT:\")\n",
    "print(f\"  - T·ªïng s·ªë d√≤ng: {total_rows}\")\n",
    "print(f\"  - S·ªë ·∫£nh unique: {unique_images}\")\n",
    "print(f\"  - S·ªë d√≤ng b·ªã l·∫∑p th·ª´a: {duplicate_rows}\")\n",
    "print(f\"  - N·∫øu x√≥a d√≤ng l·∫∑p s·∫Ω c√≤n: {unique_images} d√≤ng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f73e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë d√≤ng trong CSV: 199\n",
      "S·ªë ·∫£nh unique: 146\n",
      "S·ªë ·∫£nh b·ªã l·∫∑p: 53\n",
      "\n",
      "TH·ªêNG K√ä THEO S·ªê L·∫¶N L·∫∂P:\n",
      "  - 53 ·∫£nh xu·∫•t hi·ªán 2 l·∫ßn\n",
      "\n",
      "================================================================================\n",
      "TOP 20 ·∫¢NH B·ªä L·∫∂P NHI·ªÄU NH·∫§T:\n",
      "================================================================================\n",
      " 1. 1.jpg                - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 2. Image_44.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 3. 30.jpg               - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 4. Image_13.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 5. Image_24.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 6. Image_28.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 7. Image_3.jpg          - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 8. Image_30.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      " 9. Image_31.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "10. Image_33.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "11. Image_34.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "12. Image_39.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "13. Image_4.jpg          - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "14. Image_48.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "15. 28.jpg               - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "16. Image_49.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "17. Image_51.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "18. Image_56.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "19. Image_62.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "20. Image_65.jpg         - xu·∫•t hi·ªán 2 l·∫ßn\n",
      "\n",
      "================================================================================\n",
      "T√ìM T·∫ÆT:\n",
      "================================================================================\n",
      "T·ªïng s·ªë d√≤ng: 199\n",
      "S·ªë ·∫£nh unique: 146\n",
      "S·ªë d√≤ng th·ª´a do l·∫∑p: 53\n",
      "N·∫øu gi·ªØ 1 d√≤ng/·∫£nh s·∫Ω c√≤n: 146 d√≤ng\n",
      "\n",
      "ƒê√£ xu·∫•t chi ti·∫øt v√†o file: /home/hungnq/hungnq/sd_stuff/notebook/experiment_2/duplicated_images_analysis.txt\n"
     ]
    }
   ],
   "source": [
    "# T√≥m t·∫Øt ng·∫Øn g·ªçn v·ªÅ ·∫£nh b·ªã l·∫∑p\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"/home/hungnq/hungnq/sd_stuff/notebook/experiment_2\")\n",
    "csv_file = base_path / \"prompt_base_and_variations_full.csv\"\n",
    "\n",
    "# ƒê·ªçc CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# T√¨m ·∫£nh b·ªã l·∫∑p\n",
    "image_counts = df['Images'].value_counts()\n",
    "duplicated_images = image_counts[image_counts > 1]\n",
    "\n",
    "print(f\"T·ªïng s·ªë d√≤ng trong CSV: {len(df)}\")\n",
    "print(f\"S·ªë ·∫£nh unique: {df['Images'].nunique()}\")\n",
    "print(f\"S·ªë ·∫£nh b·ªã l·∫∑p: {len(duplicated_images)}\")\n",
    "print()\n",
    "\n",
    "# Th·ªëng k√™ theo s·ªë l·∫ßn l·∫∑p\n",
    "print(\"TH·ªêNG K√ä THEO S·ªê L·∫¶N L·∫∂P:\")\n",
    "duplicate_count_stats = duplicated_images.value_counts().sort_index()\n",
    "for count, num_images in duplicate_count_stats.items():\n",
    "    print(f\"  - {num_images} ·∫£nh xu·∫•t hi·ªán {count} l·∫ßn\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(f\"TOP 20 ·∫¢NH B·ªä L·∫∂P NHI·ªÄU NH·∫§T:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, (img_name, count) in enumerate(duplicated_images.head(20).items(), 1):\n",
    "    print(f\"{idx:2d}. {img_name:20s} - xu·∫•t hi·ªán {count} l·∫ßn\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"T√ìM T·∫ÆT:\")\n",
    "print(\"=\"*80)\n",
    "total_rows = len(df)\n",
    "unique_images = df['Images'].nunique()\n",
    "duplicate_rows = total_rows - unique_images\n",
    "\n",
    "print(f\"T·ªïng s·ªë d√≤ng: {total_rows}\")\n",
    "print(f\"S·ªë ·∫£nh unique: {unique_images}\")\n",
    "print(f\"S·ªë d√≤ng th·ª´a do l·∫∑p: {duplicate_rows}\")\n",
    "print(f\"N·∫øu gi·ªØ 1 d√≤ng/·∫£nh s·∫Ω c√≤n: {unique_images} d√≤ng\")\n",
    "\n",
    "# Xu·∫•t danh s√°ch ƒë·∫ßy ƒë·ªß c√°c ·∫£nh b·ªã l·∫∑p ra file\n",
    "output_file = base_path / \"duplicated_images_analysis.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"DANH S√ÅCH ·∫¢NH B·ªä L·∫∂P TRONG CSV\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    for img_name, count in duplicated_images.items():\n",
    "        f.write(f\"\\n{img_name}: xu·∫•t hi·ªán {count} l·∫ßn\\n\")\n",
    "        \n",
    "        # L·∫•y t·∫•t c·∫£ c√°c d√≤ng c·ªßa ·∫£nh n√†y\n",
    "        img_rows = df[df['Images'] == img_name]\n",
    "        \n",
    "        for idx, row in img_rows.iterrows():\n",
    "            f.write(f\"  D√≤ng {idx + 2}: gender={row['gender']}\\n\")\n",
    "            \n",
    "            # Ki·ªÉm tra prompts\n",
    "            prompts_info = []\n",
    "            if pd.notna(row['base_prompt']):\n",
    "                prompts_info.append(\"base_prompt\")\n",
    "            if pd.notna(row.get('variation_1_prompt')):\n",
    "                prompts_info.append(\"variation_1\")\n",
    "            if pd.notna(row.get('variation_2_prompt')):\n",
    "                prompts_info.append(\"variation_2\")\n",
    "            if pd.notna(row.get('variation_3_prompt')):\n",
    "                prompts_info.append(\"variation_3\")\n",
    "            if pd.notna(row.get('variation_4_prompt')):\n",
    "                prompts_info.append(\"variation_4\")\n",
    "            \n",
    "            if prompts_info:\n",
    "                f.write(f\"         C√≥: {', '.join(prompts_info)}\\n\")\n",
    "\n",
    "print(f\"\\nƒê√£ xu·∫•t chi ti·∫øt v√†o file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89841ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PH√ÇN T√çCH CHI TI·∫æT 2 FOLDERS C√ì √çT ·∫¢NH\n",
      "================================================================================\n",
      "\n",
      "üìÅ prompt_variations_images_batch_0_50_2\n",
      "--------------------------------------------------------------------------------\n",
      "S·ªë entries trong metadata.json: 38\n",
      "S·ªë image folders: 38\n",
      "T·ªïng s·ªë ·∫£nh th·ª±c t·∫ø: 38\n",
      "Folders tr·ªëng: 0\n",
      "\n",
      "Ph√¢n lo·∫°i ·∫£nh theo lo·∫°i:\n",
      "  - base_male: 38 ·∫£nh\n",
      "\n",
      "Ph√¢n t√≠ch metadata:\n",
      "Metadata entries theo prompt_type:\n",
      "  - base: 38 entries\n",
      "\n",
      "S·ªë image_id unique trong metadata: 38\n",
      "Image IDs range: 1 - 47\n",
      "Image IDs b·ªã thi·∫øu (9): [32, 35, 37, 40, 41, 42, 43, 45, 46]\n",
      "\n",
      "üìÅ prompt_variations_images_batch_100_150\n",
      "--------------------------------------------------------------------------------\n",
      "S·ªë entries trong metadata.json: 36\n",
      "S·ªë image folders: 37\n",
      "T·ªïng s·ªë ·∫£nh th·ª±c t·∫ø: 36\n",
      "Folders tr·ªëng: 1\n",
      "  Danh s√°ch folders tr·ªëng: ['image_0037']\n",
      "\n",
      "Ph√¢n lo·∫°i ·∫£nh theo lo·∫°i:\n",
      "  - base_female: 36 ·∫£nh\n",
      "\n",
      "Ph√¢n t√≠ch metadata:\n",
      "Metadata entries theo prompt_type:\n",
      "  - base: 36 entries\n",
      "\n",
      "S·ªë image_id unique trong metadata: 36\n",
      "Image IDs range: 2 - 42\n",
      "Image IDs b·ªã thi·∫øu (5): [35, 36, 37, 39, 40]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ƒêi·ªÅu tra t·∫°i sao prompt_variations_images_batch_0_50_2 v√† batch_100_150 ch·ªâ c√≥ ~30-40 ·∫£nh\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "base_path = Path(\"/home/hungnq/hungnq/sd_stuff/notebook/experiment_2\")\n",
    "\n",
    "# Danh s√°ch c√°c folders c·∫ßn ki·ªÉm tra\n",
    "folders_to_check = [\n",
    "    \"prompt_variations_images_batch_0_50_2\",\n",
    "    \"prompt_variations_images_batch_100_150\"\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PH√ÇN T√çCH CHI TI·∫æT 2 FOLDERS C√ì √çT ·∫¢NH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for folder_name in folders_to_check:\n",
    "    folder_path = base_path / folder_name\n",
    "    metadata_path = folder_path / \"metadata.json\"\n",
    "    \n",
    "    print(f\"\\nüìÅ {folder_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # ƒê·ªçc metadata\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"S·ªë entries trong metadata.json: {len(metadata)}\")\n",
    "    \n",
    "    # L·∫•y danh s√°ch image folders\n",
    "    image_folders = [d for d in os.listdir(folder_path) \n",
    "                    if d.startswith('image_') and os.path.isdir(folder_path / d)]\n",
    "    \n",
    "    print(f\"S·ªë image folders: {len(image_folders)}\")\n",
    "    \n",
    "    # ƒê·∫øm c√°c lo·∫°i ·∫£nh\n",
    "    image_types = {}\n",
    "    total_images = 0\n",
    "    empty_folders = []\n",
    "    \n",
    "    for img_folder in sorted(image_folders):\n",
    "        img_folder_path = folder_path / img_folder\n",
    "        images = list(img_folder_path.glob('*.png')) + list(img_folder_path.glob('*.jpg'))\n",
    "        \n",
    "        if len(images) == 0:\n",
    "            empty_folders.append(img_folder)\n",
    "        else:\n",
    "            total_images += len(images)\n",
    "            for img in images:\n",
    "                stem = img.stem  # base_male, base_female, etc.\n",
    "                image_types[stem] = image_types.get(stem, 0) + 1\n",
    "    \n",
    "    print(f\"T·ªïng s·ªë ·∫£nh th·ª±c t·∫ø: {total_images}\")\n",
    "    print(f\"Folders tr·ªëng: {len(empty_folders)}\")\n",
    "    \n",
    "    if empty_folders:\n",
    "        print(f\"  Danh s√°ch folders tr·ªëng: {empty_folders}\")\n",
    "    \n",
    "    print(f\"\\nPh√¢n lo·∫°i ·∫£nh theo lo·∫°i:\")\n",
    "    for img_type, count in sorted(image_types.items()):\n",
    "        print(f\"  - {img_type}: {count} ·∫£nh\")\n",
    "    \n",
    "    # Ph√¢n t√≠ch metadata ƒë·ªÉ xem n√™n c√≥ bao nhi√™u ·∫£nh\n",
    "    print(f\"\\nPh√¢n t√≠ch metadata:\")\n",
    "    metadata_by_type = {}\n",
    "    for key, value in metadata.items():\n",
    "        prompt_type = value.get('prompt_type', 'unknown')\n",
    "        metadata_by_type[prompt_type] = metadata_by_type.get(prompt_type, 0) + 1\n",
    "    \n",
    "    print(f\"Metadata entries theo prompt_type:\")\n",
    "    for ptype, count in sorted(metadata_by_type.items()):\n",
    "        print(f\"  - {ptype}: {count} entries\")\n",
    "    \n",
    "    # Ki·ªÉm tra image_id trong metadata\n",
    "    image_ids = set()\n",
    "    for key, value in metadata.items():\n",
    "        if 'image_id' in value:\n",
    "            image_ids.add(value['image_id'])\n",
    "    \n",
    "    print(f\"\\nS·ªë image_id unique trong metadata: {len(image_ids)}\")\n",
    "    print(f\"Image IDs range: {min(image_ids) if image_ids else 'N/A'} - {max(image_ids) if image_ids else 'N/A'}\")\n",
    "    \n",
    "    # Ki·ªÉm tra xem c√≥ image_id n√†o thi·∫øu kh√¥ng\n",
    "    if image_ids:\n",
    "        expected_range = set(range(min(image_ids), max(image_ids) + 1))\n",
    "        missing_ids = expected_range - image_ids\n",
    "        if missing_ids:\n",
    "            print(f\"Image IDs b·ªã thi·∫øu ({len(missing_ids)}): {sorted(missing_ids)[:20]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da1bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PH√ÇN T√çCH C·ªòT image_path TRONG CSV\n",
      "================================================================================\n",
      "\n",
      "T·ªïng s·ªë d√≤ng trong CSV: 199\n",
      "\n",
      "D√≤ng c√≥ image_path null (NaN): 0\n",
      "D√≤ng c√≥ image_path empty (''): 0\n",
      "D√≤ng c√≥ image_path h·ª£p l·ªá: 199\n",
      "\n",
      "================================================================================\n",
      "KI·ªÇM TRA S·ª∞ T·ªíN T·∫†I C·ª¶A FILES\n",
      "================================================================================\n",
      "\n",
      "Files t·ªìn t·∫°i: 199\n",
      "Files KH√îNG t·ªìn t·∫°i: 0\n",
      "\n",
      "================================================================================\n",
      "PH√ÇN T√çCH C·∫§U TR√öC ƒê∆Ø·ªúNG D·∫™N\n",
      "================================================================================\n",
      "\n",
      "S·ªë ƒë∆∞·ªùng d·∫´n unique: 199\n",
      "\n",
      "Ph√¢n lo·∫°i theo th∆∞ m·ª•c:\n",
      "  /home/hungnq/hungnq/sd_stuff/datahub/dataset_200/female: 100 files\n",
      "  /home/hungnq/hungnq/sd_stuff/datahub/dataset_200/male: 99 files\n"
     ]
    }
   ],
   "source": [
    "# ƒêi·ªÅu tra c·ªôt image_path trong CSV\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "base_path = Path(\"/home/hungnq/hungnq/sd_stuff/notebook/experiment_2\")\n",
    "csv_file = base_path / \"prompt_base_and_variations_full.csv\"\n",
    "\n",
    "# ƒê·ªçc CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PH√ÇN T√çCH C·ªòT image_path TRONG CSV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nT·ªïng s·ªë d√≤ng trong CSV: {len(df)}\")\n",
    "\n",
    "# Ki·ªÉm tra c·ªôt image_path c√≥ null/empty kh√¥ng\n",
    "null_image_paths = df['image_path'].isna().sum()\n",
    "empty_image_paths = (df['image_path'] == '').sum()\n",
    "\n",
    "print(f\"\\nD√≤ng c√≥ image_path null (NaN): {null_image_paths}\")\n",
    "print(f\"D√≤ng c√≥ image_path empty (''): {empty_image_paths}\")\n",
    "print(f\"D√≤ng c√≥ image_path h·ª£p l·ªá: {len(df) - null_image_paths - empty_image_paths}\")\n",
    "\n",
    "# Ki·ªÉm tra xem c√°c ƒë∆∞·ªùng d·∫´n c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KI·ªÇM TRA S·ª∞ T·ªíN T·∫†I C·ª¶A FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "existing_files = 0\n",
    "missing_files = 0\n",
    "missing_file_list = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    \n",
    "    if pd.notna(image_path) and image_path != '':\n",
    "        if os.path.exists(image_path):\n",
    "            existing_files += 1\n",
    "        else:\n",
    "            missing_files += 1\n",
    "            missing_file_list.append({\n",
    "                'row': idx + 2,  # +2 v√¨ CSV c√≥ header v√† index b·∫Øt ƒë·∫ßu t·ª´ 0\n",
    "                'image': row['Images'],\n",
    "                'gender': row['gender'],\n",
    "                'path': image_path\n",
    "            })\n",
    "\n",
    "print(f\"\\nFiles t·ªìn t·∫°i: {existing_files}\")\n",
    "print(f\"Files KH√îNG t·ªìn t·∫°i: {missing_files}\")\n",
    "\n",
    "if missing_files > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DANH S√ÅCH {min(20, len(missing_file_list))} FILES ƒê·∫¶U TI√äN KH√îNG T·ªíN T·∫†I:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for item in missing_file_list[:20]:\n",
    "        print(f\"D√≤ng {item['row']}: {item['image']} ({item['gender']})\")\n",
    "        print(f\"  Path: {item['path']}\")\n",
    "\n",
    "# Ph√¢n t√≠ch c·∫•u tr√∫c ƒë∆∞·ªùng d·∫´n\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PH√ÇN T√çCH C·∫§U TR√öC ƒê∆Ø·ªúNG D·∫™N\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# L·∫•y c√°c ƒë∆∞·ªùng d·∫´n unique\n",
    "unique_paths = df['image_path'].dropna().unique()\n",
    "print(f\"\\nS·ªë ƒë∆∞·ªùng d·∫´n unique: {len(unique_paths)}\")\n",
    "\n",
    "# Ph√¢n lo·∫°i theo th∆∞ m·ª•c\n",
    "path_prefixes = {}\n",
    "for path in unique_paths:\n",
    "    if path:\n",
    "        # L·∫•y th∆∞ m·ª•c cha\n",
    "        parent_dir = os.path.dirname(path)\n",
    "        path_prefixes[parent_dir] = path_prefixes.get(parent_dir, 0) + 1\n",
    "\n",
    "print(f\"\\nPh√¢n lo·∫°i theo th∆∞ m·ª•c:\")\n",
    "for prefix, count in sorted(path_prefixes.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {prefix}: {count} files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdstuff-hung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
