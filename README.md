# AI-Generated vs Real Images Evaluation

Há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng áº£nh AI-generated so vá»›i áº£nh tháº­t cho bÃ i toÃ¡n phÃ¢n biá»‡t áº£nh tráº» em.

## ğŸ“‹ Má»¥c tiÃªu

Chá»©ng minh tÃ­nh kháº£ thi cá»§a viá»‡c sá»­ dá»¥ng áº£nh sinh tá»« AI Ä‘á»ƒ thay tháº¿/bá»• sung dá»¯ liá»‡u tháº­t thÃ´ng qua 3 metrics:

- **Metric A (FID)**: ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ¢n thá»±c
- **Metric B (Cosine Similarity)**: ÄÃ¡nh giÃ¡ tÃ­nh nháº¥t quÃ¡n
- **Metric C (t-SNE)**: ÄÃ¡nh giÃ¡ kháº£ nÄƒng phÃ¢n tÃ¡ch

## ğŸ—ï¸ Cáº¥u trÃºc Project

```
sd_stuff/
â”œâ”€â”€ datahub/
â”‚   â”œâ”€â”€ real_images/          # áº¢nh tháº­t
â”‚   â””â”€â”€ fake_images/          # áº¢nh AI-generated
â”œâ”€â”€ models/                   # Model layer (abstract pattern)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py        # Abstract base class
â”‚   â”œâ”€â”€ inception_model.py   # InceptionV3 for FID
â”‚   â””â”€â”€ facenet_model.py     # FaceNet for similarity
â”œâ”€â”€ metrics/                  # Metrics layer (abstract pattern)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_metric.py       # Abstract base class
â”‚   â”œâ”€â”€ fid_metric.py        # Metric A: FID
â”‚   â”œâ”€â”€ cosine_similarity_metric.py  # Metric B: Cosine Similarity
â”‚   â””â”€â”€ tsne_metric.py       # Metric C: t-SNE
â”œâ”€â”€ evaluate.py              # Main script (dependency injection)
â”œâ”€â”€ example_usage.py         # Usage examples
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ ARCHITECTURE.md          # Design pattern documentation
```

### ğŸ¯ Design Pattern

- **Abstract Pattern**: Both Models and Metrics follow abstract base classes
- **Dependency Injection**: Metrics receive models from outside (not creating internally)
- **Separation of Concerns**: Models handle preprocessing/inference, Metrics handle evaluation logic

Xem chi tiáº¿t: [ARCHITECTURE.md](ARCHITECTURE.md)

## ğŸ”§ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 2. Cáº¥u trÃºc dá»¯ liá»‡u

#### Cho Metric A & B (FID vÃ  Cosine Similarity):
```
datahub/
â”œâ”€â”€ real_images/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ fake_images/
    â”œâ”€â”€ image1.jpg
    â”œâ”€â”€ image2.jpg
    â””â”€â”€ ...
```

#### Cho Metric C (t-SNE) - khuyáº¿n nghá»‹:
```
datahub/
â””â”€â”€ fake_images/
    â”œâ”€â”€ id_001/          # ID nhÃ¢n váº­t 1
    â”‚   â”œâ”€â”€ frontal.jpg
    â”‚   â”œâ”€â”€ side_45.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ id_002/          # ID nhÃ¢n váº­t 2
    â”‚   â”œâ”€â”€ frontal.jpg
    â”‚   â”œâ”€â”€ side_45.jpg
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...
```

Hoáº·c dÃ¹ng naming convention:
```
fake_images/
â”œâ”€â”€ id_001_frontal.jpg
â”œâ”€â”€ id_001_side_45.jpg
â”œâ”€â”€ id_002_frontal.jpg
â””â”€â”€ ...
```

## ğŸš€ Sá»­ dá»¥ng

### Cháº¡y táº¥t cáº£ metrics

```bash
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images
```

### Cháº¡y tá»«ng metric riÃªng láº»

```bash
# Chá»‰ cháº¡y FID
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images --metrics fid

# Chá»‰ cháº¡y Cosine Similarity
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images --metrics cosine

# Chá»‰ cháº¡y t-SNE
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images --metrics tsne

# Cháº¡y FID vÃ  t-SNE
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images --metrics fid tsne
```

### Chá»‰ Ä‘á»‹nh output directory

```bash
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images --output ./my_results
```

## ğŸ“Š Metrics Chi tiáº¿t

### Metric A: FID (FrÃ©chet Inception Distance)

**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ¢n thá»±c cá»§a áº£nh sinh so vá»›i áº£nh tháº­t

**CÃ¡ch hoáº¡t Ä‘á»™ng**:
- Sá»­ dá»¥ng InceptionV3 Ä‘á»ƒ trÃ­ch xuáº¥t features
- TÃ­nh khoáº£ng cÃ¡ch FrÃ©chet giá»¯a phÃ¢n phá»‘i features cá»§a áº£nh tháº­t vÃ  áº£nh sinh
- **áº¢nh pháº£i 1024x1024 selfie** (theo yÃªu cáº§u senior)

**ÄÃ¡nh giÃ¡**:
- `FID < 50`: âœ“ **Äáº¡t chuáº©n** - Excellent
- `FID 50-100`: âœ“ Good
- `FID 100-200`: âš  Acceptable
- `FID > 200`: âœ— **Tháº¥t báº¡i** - Poor

**Output**: 
- `fid_results_TIMESTAMP.json`

### Metric B: Cosine Similarity

**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ tÃ­nh nháº¥t quÃ¡n cá»§a cÃ¹ng má»™t ID khi thay Ä‘á»•i gÃ³c chá»¥p/Ã¡nh sÃ¡ng

**CÃ¡ch hoáº¡t Ä‘á»™ng**:
- Sá»­ dá»¥ng FaceNet (InceptionResnetV1) Ä‘á»ƒ trÃ­ch xuáº¥t face embeddings
- TÃ­nh cosine similarity giá»¯a cÃ¡c cáº·p áº£nh
- So sÃ¡nh áº£nh cá»§a cÃ¹ng ID vá»›i cÃ¡c gÃ³c/Ä‘iá»u kiá»‡n khÃ¡c nhau

**ÄÃ¡nh giÃ¡**:
- `Similarity > 0.7`: âœ“ **Äáº¡t chuáº©n** - CÃ¹ng má»™t ngÆ°á»i, Ä‘á»™ tin cáº­y cao
- `Similarity 0.5-0.7`: âš  **Cáº§n kiá»ƒm tra** - CÃ¹ng ngÆ°á»i nhÆ°ng cÃ³ biáº¿n thiÃªn
- `Similarity < 0.5`: âœ— **Tháº¥t báº¡i** - Model coi lÃ  2 ngÆ°á»i khÃ¡c nhau

**Output**: 
- `cosine_similarity_results_TIMESTAMP.json`

### Metric C: t-SNE Visualization

**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ kháº£ nÄƒng phÃ¢n tÃ¡ch cÃ¡c ID nhÃ¢n váº­t áº£o khÃ¡c nhau

**CÃ¡ch hoáº¡t Ä‘á»™ng**:
- TrÃ­ch xuáº¥t face embeddings cho táº¥t cáº£ áº£nh
- Ãp dá»¥ng t-SNE Ä‘á»ƒ giáº£m chiá»u xuá»‘ng 2D
- Visualize vÃ  tÃ­nh separation ratio

**ÄÃ¡nh giÃ¡**:
- `Separation Ratio > 2.0`: âœ“ **Äáº¡t chuáº©n** - Excellent separation
- `Separation Ratio 1.5-2.0`: âœ“ Good separation
- `Separation Ratio < 1.5`: âœ— **Tháº¥t báº¡i** - Poor separation (overlap nhiá»u)

**Output**: 
- `tsne_results_TIMESTAMP.json`
- `tsne_visualization_TIMESTAMP.png` - Biá»ƒu Ä‘á»“ 2D

## ğŸ“ Output Format

### JSON Results Example

```json
{
  "timestamp": "20231208_143022",
  "real_path": "./datahub/real_images",
  "fake_path": "./datahub/fake_images",
  "metrics": {
    "fid": {
      "metric": "FID",
      "score": 45.32,
      "num_real_images": 100,
      "num_fake_images": 100,
      "interpretation": "âœ“ Äáº T CHUáº¨N - Excellent..."
    },
    "cosine_similarity": {
      "metric": "Cosine Similarity",
      "average_similarity": 0.78,
      "std_similarity": 0.12,
      "min_similarity": 0.65,
      "max_similarity": 0.92,
      "interpretation": "âœ“ Äáº T CHUáº¨N..."
    },
    "tsne": {
      "metric": "t-SNE",
      "num_ids": 5,
      "total_images": 50,
      "cluster_metrics": {
        "avg_intra_cluster_distance": 0.45,
        "avg_inter_cluster_distance": 1.23,
        "separation_ratio": 2.73
      },
      "interpretation": "âœ“ Äáº T CHUáº¨N - Excellent..."
    }
  }
}
```

## ğŸ¯ Use Cases

### Use Case 1: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng tá»•ng thá»ƒ
```bash
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images
```
â†’ Cháº¡y táº¥t cáº£ 3 metrics Ä‘á»ƒ cÃ³ overview hoÃ n chá»‰nh

### Use Case 2: Test tÃ­nh nháº¥t quÃ¡n cá»§a 1 ID
```bash
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images --metrics cosine
```
â†’ Kiá»ƒm tra xem cÃ¡c áº£nh cá»§a cÃ¹ng ID cÃ³ consistent khÃ´ng

### Use Case 3: Visualize phÃ¢n bá»‘ cÃ¡c ID
```bash
python evaluate.py --real-path ./datahub/real_images --fake-path ./datahub/fake_images --metrics tsne
```
â†’ Táº¡o biá»ƒu Ä‘á»“ 2D Ä‘á»ƒ quan sÃ¡t sá»± phÃ¢n tÃ¡ch

## ğŸ”¬ Technical Notes

### Image Requirements

- **Format**: JPG, PNG, BMP, WEBP
- **Size**: Khuyáº¿n nghá»‹ 1024x1024 (theo yÃªu cáº§u cá»§a senior vá» pixel-to-pixel comparison)
- **Type**: Selfie, chá»¥p khuÃ´n máº·t rÃµ rÃ ng
- **Sá»‘ lÆ°á»£ng**: 
  - FID: 50-100 áº£nh má»—i táº­p (real & fake)
  - Cosine: Tá»‘i thiá»ƒu 2 áº£nh cÃ¹ng ID
  - t-SNE: 5-10 IDs, má»—i ID ~10 áº£nh

### Model Dependencies

- **FID**: InceptionV3 (pretrained on ImageNet) - khá»Ÿi táº¡o qua `InceptionModel`
- **Cosine Similarity**: FaceNet (InceptionResnetV1 pretrained on VGGFace2) - khá»Ÿi táº¡o qua `FaceNetModel`
- **t-SNE**: Same as Cosine Similarity

### Architecture

Models vÃ  Metrics Ä‘Æ°á»£c tÃ¡ch biá»‡t:
- **Models** (`models/`): Xá»­ lÃ½ preprocessing, inference, postprocessing
- **Metrics** (`metrics/`): Business logic Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
- **Dependency Injection**: Models Ä‘Æ°á»£c inject vÃ o Metrics tá»« bÃªn ngoÃ i
## ğŸ› Troubleshooting

### Lá»—i: "FIDMetric requires an InceptionModel instance"
â†’ Metrics cáº§n model Ä‘Æ°á»£c inject tá»« bÃªn ngoÃ i. Xem `example_usage.py`

### Lá»—i: "No images found"
â†’ Kiá»ƒm tra Ä‘Æ°á»ng dáº«n vÃ  format file (jpg, png, etc.)

- GPU khuyáº¿n nghá»‹ cho xá»­ lÃ½ nhanh
- CPU váº«n cháº¡y Ä‘Æ°á»£c nhÆ°ng cháº­m hÆ¡n
- Batch processing Ä‘á»ƒ tá»‘i Æ°u memory

## ğŸ› Troubleshooting

### Lá»—i: "No images found"
â†’ Kiá»ƒm tra Ä‘Æ°á»ng dáº«n vÃ  format file (jpg, png, etc.)

### Lá»—i: "Not enough images"
â†’ Äáº£m báº£o cÃ³ Ä‘á»§ sá»‘ lÆ°á»£ng áº£nh theo yÃªu cáº§u má»—i metric

### Lá»—i: "facenet_pytorch not found"
â†’ Code tá»± Ä‘á»™ng fallback vá» ResNet50, váº«n cháº¡y Ä‘Æ°á»£c nhÆ°ng accuracy cÃ³ thá»ƒ tháº¥p hÆ¡n

### FID score quÃ¡ cao
â†’ Kiá»ƒm tra:
- áº¢nh cÃ³ Ä‘Ãºng size 1024x1024?
- áº¢nh cÃ³ cÃ¹ng style/domain khÃ´ng?
- Cháº¥t lÆ°á»£ng áº£nh sinh cÃ³ tá»‘t khÃ´ng?

## ğŸ“š References

- [FID Paper](https://arxiv.org/abs/1706.08500)
- [FaceNet Paper](https://arxiv.org/abs/1503.03832)
- [t-SNE Paper](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)

## ğŸ‘¥ Contributors

Developed for AI-generated children images evaluation project.

---

**Note**: ÄÃ¢y lÃ  code evaluation, khÃ´ng bao gá»“m pháº§n generation áº£nh. Chá»‰ Ä‘Ã¡nh giÃ¡ áº£nh cÃ³ sáºµn trong `datahub`.
